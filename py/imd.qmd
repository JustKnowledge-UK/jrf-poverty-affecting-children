---
title: "IMD"
author: Jolyon Miles-Wilson
date: 2025-07-01
format: 
    html:
        embed-resource: true
        code-fold: true
        warning: false
---

This script plots the indices of deprivation for MSOAs within Haringey, highlighting the Northumberland Park MSOA. Indices of deprivation data can be retrieved from https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019.

```{python}
import psycopg2
import configparser
import os
import requests
import pandas as pd
from sqlalchemy import create_engine
import matplotlib.pyplot as plt
from sqlalchemy import create_engine

# Load DB config
config = configparser.ConfigParser()
config.read(os.path.join('..', 'db_config.ini'))
db_params = dict(config['postgresql'])

# Build SQLAlchemy connection string
conn_str = (
    f"postgresql+psycopg2://{db_params['user']}:{db_params['password']}"
    f"@{db_params['host']}:{db_params['port']}/{db_params['database']}"
)

# Create engine
engine = create_engine(conn_str)

```

Read in the IoD data, a LSOA-MSOA lookup, and population estimates for aggregating using population weights.

Data sources:

- IoD: https://www.gov.uk/government/statistics/english-indices-of-deprivation-2019
- Lookup: https://geoportal.statistics.gov.uk/datasets/ons::output-area-2021-to-lsoas-to-msoas-to-lep-to-lad-may-2022-best-fit-lookup-in-en/about
- Population estimates: https://www.nomisweb.co.uk/datasets/pestoa2021

```{python}
# Read IOD from treehouse
with engine.connect() as con:
    query = '''SELECT *
                FROM iod_2019
                '''

    iod = pd.read_sql(query, con = con)

    query2 = '''SELECT DISTINCT lsoa11cd, msoa11cd, lad21nm
            FROM pcode_census11_lookup
        '''
    lookup = pd.read_sql(query2, con = con)

    query3 = '''SELECT lsoa11cd, population 
                FROM population_lsoa
            '''

    pop = pd.read_sql(query3, con=con)

iod.columns = (
    iod.columns
    .str.replace(',', '', regex=True)   # Remove ','
    .str.replace('index_idaci_','', regex=True) # Remove suffix for income affecting children
    .str.replace('idaopi_','', regex=True) # Remove suffix for income affecting older people
)

```

```{python}
# Aggregate scores up to msoa
iod = (iod
    .merge(lookup, how='left',on='lsoa11cd')
    .merge(pop, how='left', on='lsoa11cd')
)
cols = iod.columns[iod.columns.str.contains('score')]

iod2 = iod.copy()

# Multiply each score by population
for col in cols:
    iod2[col + '_weighted'] = iod2[col] * iod2['population']

# Group by MSOA and sum the weighted scores and population
grouped = iod2.groupby(['msoa11cd','lad21nm']).agg(
    {col + '_weighted': 'sum' for col in cols} |
    {'population': 'sum'}
).reset_index()


# Calculate weighted average, rank, and decile
for col in cols:
    avg_col = col + '_weighted_avg'
    rank_col = col + '_rank'
    decile_col = col + '_decile'

    grouped[avg_col] = grouped[col + '_weighted'] / grouped['population']
    grouped[rank_col] = grouped[avg_col].rank(method='min', ascending=False)
    grouped[decile_col] = pd.qcut(grouped[rank_col], q=10, labels=range(1, 11), duplicates='drop')

# Select final columns to keep
iod_msoa = grouped[['msoa11cd', 'lad21nm'] + 
                   [col + suffix for col in cols for suffix in ['_weighted_avg', '_rank', '_decile']]]


```

Plot IOD for Haringey, highlighting Northumberland Park MSOA in black and other Haringey MSOAs in grey.

```{python}
# Select subset of domains so plot isn't information overload
domains_of_interest = [
    'income',
    'employment',
    'education_skills_and_training',
    'health_deprivation_and_disability',
    'crime',
    'barriers_to_housing_and_services',
    'living_environment',
    'income_deprivation_affecting_children',
    'income_deprivation_affecting_older_people',
    'children_and_young_people_sub-domain',
    'adult_skills_sub-domain',
    'geographical_barriers_sub-domain',
    'wider_barriers_sub-domain',
    'indoors_sub-domain',
    'outdoors_sub-domain',
]

# Reorder columns
rank_cols = [
    col for col in iod_msoa.columns
    if 'rank' in col
    and any(domain in col for domain in domains_of_interest)
]


iod_msoa_ranks = iod_msoa[['msoa11cd','lad21nm'] + rank_cols]


haringey_ranks = iod_msoa_ranks[iod_msoa_ranks['lad21nm']=='Haringey']

# Pivot longer
haringey_ranks_long = haringey_ranks.melt(
    id_vars = 'msoa11cd',
    value_vars = rank_cols,
    var_name = 'domain',
    value_name = 'rank')

# Clean up domain names (remove '_rank' suffix)
haringey_ranks_long['domain'] = haringey_ranks_long['domain'].str.replace('_score_rate_rank', '')
haringey_ranks_long['domain'] = haringey_ranks_long['domain'].str.replace('_score_rank', '')
# Make title case and swap underscores for spaces 
domains_of_interest = haringey_ranks_long['domain'].unique()
def clean_domain_name(domain):
    return domain.replace('_', ' ').title()
domain_dict = {domain: clean_domain_name(domain) for domain in domains_of_interest}
# Apply the mapping to the dataframe
haringey_ranks_long['clean_domain'] = haringey_ranks_long['domain'].map(domain_dict)

# Specify the Northumberland Park MSOA
np_msoas = ['E02000398']

np_data = haringey_ranks_long[haringey_ranks_long['msoa11cd'].isin(np_msoas)]
not_np_data = haringey_ranks_long[~haringey_ranks_long['msoa11cd'].isin(np_msoas)]

# Create color list
colors = ['black' if msoa in np_msoas else 'lightgrey' 
        for msoa in haringey_ranks_long['msoa11cd']]

max_rank = int(iod_msoa_ranks[rank_cols].max().max())

# Get the bin edges for deciles
# Create all ranks obejct
all_ranks = range(1,max_rank) # 32844 + 1
total_ranks = len(all_ranks)

# Calculate decile boundaries (every 10%)
decile_boundaries = []
for i in range(0, 10):  # Deciles 1-9 (10th decile goes to the end)
    boundary_index = int(i * total_ranks / 10)
    decile_boundaries.append(all_ranks[boundary_index])

# Add in the last edge
decile_boundaries.append(max(all_ranks))

fig, ax = plt.subplots(figsize=[6,6])

# Plot grey points first (bottom layer)
ax.scatter(not_np_data['rank'], not_np_data['clean_domain'], c='lightgrey')

# Plot black points second (top layer)
ax.scatter(np_data['rank'], np_data['clean_domain'], c='black')

# Add vertical lines for decile boundaries
for i, boundary in enumerate(decile_boundaries):
    ax.axvline(
        x=boundary, 
        color='red', 
        # linestyle=(0, (5, 10)), 
        linestyle='dotted', 
        alpha=0.7)
    if i < 10:
        x_loc = (decile_boundaries[i] + decile_boundaries[i+1]) / 2
        ax.text(x=x_loc, y=ax.get_ylim()[0]*1.2, s=i+1, ha='center')

plt.xlabel('Rank')

ax.text(x=ax.get_xlim()[0], y=ax.get_ylim()[0]*1.2, s='Decile', ha='right')

ax.text(x=ax.get_xlim()[1], y=ax.get_ylim()[1]*1.25, s='Black dots indicate Northumberland Park\nGrey dots represent other areas in Haringey', wrap=False, horizontalalignment='right', fontsize=10)
ax.invert_yaxis()
plt.tight_layout()
# Add title with specific positioning
# plt.title('Deprivation in Haringey', fontsize=14, x=0, y=1.05, ha='left')  # y controls vertical position
plt.show()

fig.savefig(os.path.join('..','outputs','deprivation.png'), dpi=800)
```